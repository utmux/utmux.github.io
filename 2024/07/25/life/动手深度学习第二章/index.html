<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="天气：晴天	心情：差   第二章  广播机制 对于矩阵不匹配时，此时会进行广播，即找到最小公共大小的矩阵，将两个矩阵都扩展到该大小后，再计算，如下： 12a &#x3D; torch.arange(3).reshape((3, 1))b &#x3D; torch.arange(2).reshape((1, 2)) 此时最小公共矩阵的大小为3x2，即a复制行变为3x2，b复制列为3x2，此时执行 1a+b 对输出广播后">
<meta property="og:type" content="article">
<meta property="og:title" content="动手深度学习第二章">
<meta property="og:url" content="https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/index.html">
<meta property="og:site_name" content="混吃等死">
<meta property="og:description" content="天气：晴天	心情：差   第二章  广播机制 对于矩阵不匹配时，此时会进行广播，即找到最小公共大小的矩阵，将两个矩阵都扩展到该大小后，再计算，如下： 12a &#x3D; torch.arange(3).reshape((3, 1))b &#x3D; torch.arange(2).reshape((1, 2)) 此时最小公共矩阵的大小为3x2，即a复制行变为3x2，b复制列为3x2，此时执行 1a+b 对输出广播后">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-07-25T06:45:26.000Z">
<meta property="article:modified_time" content="2024-09-13T02:08:29.115Z">
<meta property="article:author" content="YQX">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>动手深度学习第二章</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body class="max-width mx-auto px3 ltr">    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="顶部" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/categories/">分类</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/utmux">项目</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="上一篇" href="/2024/07/29/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E7%AB%A0/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="下一篇" href="/2024/06/21/life/%E5%85%B3%E4%BA%8E%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0%E5%92%8C%E6%A8%A1%E6%9D%BF%E7%B1%BB%E4%B8%AD%E7%9A%84static%E5%8F%98%E9%87%8F/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="返回顶部" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="分享文章" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&text=动手深度学习第二章"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&is_video=false&description=动手深度学习第二章"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=动手深度学习第二章&body=Check out this article: https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&name=动手深度学习第二章&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&t=动手深度学习第二章"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0"><span class="toc-number">1.</span> <span class="toc-text"> 第二章</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6"><span class="toc-number">1.0.1.</span> <span class="toc-text"> 广播机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E6%9C%BA%E5%88%B6"><span class="toc-number">1.0.2.</span> <span class="toc-text"> 索引机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8E%9F%E5%9C%B0%E6%93%8D%E4%BD%9Cin-place-operation"><span class="toc-number">1.0.3.</span> <span class="toc-text"> 原地操作（in-place operation）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tensor%E4%B8%8Enumpy%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E5%8C%96"><span class="toc-number">1.0.4.</span> <span class="toc-text"> tensor与numpy的相互转化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5%E7%94%A8chatgpt"><span class="toc-number">1.0.5.</span> <span class="toc-text"> 读取数据集（可以省略用chatgpt）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%99%E5%85%A5csv"><span class="toc-number">1.0.6.</span> <span class="toc-text"> 写入CSV：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96csv"><span class="toc-number">1.0.7.</span> <span class="toc-text"> 读取CSV</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E6%97%A0%E6%95%88%E6%95%B0%E5%80%BC"><span class="toc-number">1.0.8.</span> <span class="toc-text"> 填充无效数值</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#one-hot%E7%BC%96%E7%A0%81"><span class="toc-number">1.0.9.</span> <span class="toc-text"> one-hot编码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86panda%E8%AF%BB%E5%8F%96%E7%9A%84csv%E6%95%B0%E6%8D%AE%E8%BD%AC%E5%8C%96%E4%B8%BAtensor"><span class="toc-number">1.0.10.</span> <span class="toc-text"> 将panda读取的csv数据转化为tensor</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8C%89%E5%85%83%E7%B4%A0%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E9%BB%98%E8%AE%A4%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E7%AC%A6%E5%8F%B7%E9%83%BD%E6%98%AF%E6%8C%89%E5%85%83%E7%B4%A0%E8%AE%A1%E7%AE%97%E5%8D%B3%E7%82%B9%E5%8A%A0%E7%82%B9%E4%B9%98"><span class="toc-number">1.0.11.</span> <span class="toc-text"> 按元素加减乘除（默认情况下的加减乘除符号都是按元素计算，即点加，点乘）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B1%82%E5%92%8C%E8%BF%90%E7%AE%97"><span class="toc-number">1.0.12.</span> <span class="toc-text"> 求和运算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B1%82%E5%B9%B3%E5%9D%87%E8%BF%90%E7%AE%97"><span class="toc-number">1.0.13.</span> <span class="toc-text"> 求平均运算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%82%B9%E7%A7%AFx%E4%B8%8Ey%E5%9E%82%E7%9B%B4"><span class="toc-number">1.0.14.</span> <span class="toc-text"> 点积（x与y垂直）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="toc-number">1.0.15.</span> <span class="toc-text"> 矩阵乘法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%8C%83%E6%95%B0"><span class="toc-number">1.0.16.</span> <span class="toc-text"> 范数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86"><span class="toc-number">1.0.17.</span> <span class="toc-text"> 自动微分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9D%9E%E6%A0%87%E9%87%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">1.0.18.</span> <span class="toc-text"> 非标量变量的反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">1.0.19.</span> <span class="toc-text"> 分离计算</span></a></li></ol></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        动手深度学习第二章
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">YQX</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-07-25T06:45:26.000Z" class="dt-published" itemprop="datePublished">2024-07-25</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/life/">life</a>
    </div>


      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>天气：晴天	心情：差</p>
<hr />
<h3 id="第二章"><a class="markdownIt-Anchor" href="#第二章"></a> 第二章</h3>
<h5 id="广播机制"><a class="markdownIt-Anchor" href="#广播机制"></a> 广播机制</h5>
<p>对于矩阵不匹配时，此时会进行广播，即找到最小公共大小的矩阵，将两个矩阵都扩展到该大小后，再计算，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.arange(<span class="number">3</span>).reshape((<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">b = torch.arange(<span class="number">2</span>).reshape((<span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>此时最小公共矩阵的大小为3x2，即a复制行变为3x2，b复制列为3x2，此时执行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a+b</span><br></pre></td></tr></table></figure>
<p>对输出广播后的结果</p>
<h5 id="索引机制"><a class="markdownIt-Anchor" href="#索引机制"></a> 索引机制</h5>
<p>和matlab中类似，不同的是，这里-1代表最后一个元素，且从0开始。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x[<span class="number">1</span>,<span class="number">2</span>]	<span class="comment">#选择1和2</span></span><br><span class="line">x[<span class="number">1</span>,:]	<span class="comment">#选择第一行</span></span><br><span class="line">x[<span class="number">1</span>:<span class="number">3</span>]	<span class="comment">#选择1-3</span></span><br></pre></td></tr></table></figure>
<h5 id="原地操作in-place-operation"><a class="markdownIt-Anchor" href="#原地操作in-place-operation"></a> 原地操作（in-place operation）</h5>
<p>为了减少内存使用，在 PyTorch 中，原地操作通常通过在函数名后添加下划线（<code>_</code>）来实现。比如：</p>
<ul>
<li><code>add_()</code>：原地加法。</li>
<li><code>sub_()</code>：原地减法。</li>
<li><code>mul_()</code>：原地乘法。</li>
<li><code>div_()</code>：原地除法。</li>
<li><code>abs_()</code>：原地取绝对值。</li>
<li><code>matmul_()</code>：原地矩阵乘法。</li>
<li>逐元素操作，如 <code>mul_()</code> 和 <code>div_()</code>，也可以是原地的。</li>
</ul>
<p>我们也可以通过切片操作来实现in-place</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y[:] = &lt;expression&gt;</span><br></pre></td></tr></table></figure>
<h5 id="tensor与numpy的相互转化"><a class="markdownIt-Anchor" href="#tensor与numpy的相互转化"></a> tensor与numpy的相互转化</h5>
<p>我们可以通过下面的代码，将numpy数组转化为tensor（torch张量和numpy数<br />
组将<strong>共享它们的底层内存</strong>，就地操作更改一个张量也会同时更改另一个张量。）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A = X.numpy()</span><br><span class="line">B = torch.tensor(A)</span><br></pre></td></tr></table></figure>
<p>我们也可以将tensor转化为python标量，我们可以调用item函数或Python的内置函数，如下的几种方法都能够将tensor标量转化为python标量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">3.5</span>]) <span class="comment">#a是一个tensor标量</span></span><br><span class="line">a.item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a) <span class="comment">#这三种方法都可以将tensor转化为python标量</span></span><br></pre></td></tr></table></figure>
<h5 id="读取数据集可以省略用chatgpt"><a class="markdownIt-Anchor" href="#读取数据集可以省略用chatgpt"></a> 读取数据集（可以省略用chatgpt）</h5>
<p>常用代码段：</p>
<h5 id="写入csv"><a class="markdownIt-Anchor" href="#写入csv"></a> 写入CSV：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.makedirs(os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>), exist_ok=<span class="literal">True</span>)</span><br><span class="line">data_file = os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">f.write(<span class="string">&#x27;NumRooms,Alley,Price\n&#x27;</span>)</span><br><span class="line"><span class="comment"># 列名</span></span><br><span class="line">f.write(<span class="string">&#x27;NA,Pave,127500\n&#x27;</span>)</span><br><span class="line"><span class="comment"># 每行表示一个数据样本</span></span><br><span class="line">f.write(<span class="string">&#x27;2,NA,106000\n&#x27;</span>)</span><br><span class="line">f.write(<span class="string">&#x27;4,NA,178100\n&#x27;</span>)</span><br><span class="line">f.write(<span class="string">&#x27;NA,NA,140000\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5 id="读取csv"><a class="markdownIt-Anchor" href="#读取csv"></a> 读取CSV</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(data_file)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>
<h5 id="填充无效数值"><a class="markdownIt-Anchor" href="#填充无效数值"></a> 填充无效数值</h5>
<p>我们可以对读取的CSV中的Nan，即无效数值进行填充，比如填充为均值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inputs, outputs = data.iloc[:, <span class="number">0</span>:<span class="number">2</span>], data.iloc[:, <span class="number">2</span>] <span class="comment">#注意Python 中的切片是左闭右开区间，即包含0，不包含2</span></span><br><span class="line">inputs = inputs.fillna(inputs.mean())</span><br></pre></td></tr></table></figure>
<h5 id="one-hot编码"><a class="markdownIt-Anchor" href="#one-hot编码"></a> one-hot编码</h5>
<p>我们可以将panda读取的CSV中的类别转化成one-hot编码，即从文本变成数字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies()</span><br></pre></td></tr></table></figure>
<p>除此外，我们可以在编码过程中，如果存在缺失值（即 NaN），也会为它们创建一个单独的指示变量。如果没有设置这个参数或设置为 <code>False</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inputs = pd.get_dummies(inputs, dummy_na=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h5 id="将panda读取的csv数据转化为tensor"><a class="markdownIt-Anchor" href="#将panda读取的csv数据转化为tensor"></a> 将panda读取的csv数据转化为tensor</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor(inputs.to_numpy(dtype=<span class="built_in">float</span>))</span><br><span class="line">y = torch.tensor(outputs.to_numpy(dtype=<span class="built_in">float</span>))</span><br><span class="line"><span class="comment"># 先转化为numpy，再转化为tensor</span></span><br></pre></td></tr></table></figure>
<h5 id="按元素加减乘除默认情况下的加减乘除符号都是按元素计算即点加点乘"><a class="markdownIt-Anchor" href="#按元素加减乘除默认情况下的加减乘除符号都是按元素计算即点加点乘"></a> 按元素加减乘除（默认情况下的加减乘除符号都是按元素计算，即点加，点乘）</h5>
<p>默认情况下使用<code>+</code>，<code>-</code>，<code>*</code>，<code>/</code>是相当点加，点减和点乘与点除（如果维度不同，则先广播）</p>
<h5 id="求和运算"><a class="markdownIt-Anchor" href="#求和运算"></a> 求和运算</h5>
<p>我们可以通过sum来进行求和运算，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A.<span class="built_in">sum</span>(axis=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 结果和A.sum()相同,默认情况的sum()对所有轴求和</span></span><br></pre></td></tr></table></figure>
<p>上面收缩了轴数，我们可以保持轴数不变：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum_A = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>如果我们想沿某个轴计算A元素的累积总和，比如axis=0（按行计算），可以调用cumsum函数。此函数不会沿任何轴降低输入张量的维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h5 id="求平均运算"><a class="markdownIt-Anchor" href="#求平均运算"></a> 求平均运算</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A.mean(), A.<span class="built_in">sum</span>() / A.numel()</span><br><span class="line">A.mean(axis=<span class="number">0</span>), A.<span class="built_in">sum</span>(axis=<span class="number">0</span>) / A.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h5 id="点积x与y垂直"><a class="markdownIt-Anchor" href="#点积x与y垂直"></a> 点积（x与y垂直）</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.dot(x, y)</span><br></pre></td></tr></table></figure>
<p>注意，我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">sum</span>(x * y)</span><br></pre></td></tr></table></figure>
<h5 id="矩阵乘法"><a class="markdownIt-Anchor" href="#矩阵乘法"></a> 矩阵乘法</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.mm(A, B)</span><br></pre></td></tr></table></figure>
<h5 id="范数"><a class="markdownIt-Anchor" href="#范数"></a> 范数</h5>
<p>满足下面三个性质，即是范数：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>α</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><mi>α</mi><mi mathvariant="normal">∣</mi><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mspace linebreak="newline"></mspace><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo>+</mo><mi mathvariant="bold">y</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi><mspace linebreak="newline"></mspace><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>≥</mo><mn>0.</mn></mrow><annotation encoding="application/x-tex">f(\alpha\mathbf{x})=|\alpha|f(\mathbf{x}).\\
f(\mathbf{x}+\mathbf{y})\leq f(\mathbf{x})+f(\mathbf{y}).\\
f(\mathbf{x})\geq0.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mord">.</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span><span class="mclose">)</span><span class="mord">.</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathbf">x</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span></span></span></span></span></p>
<p>向量的范数有L1，L2，分别表示如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.<span class="built_in">abs</span>(u).<span class="built_in">sum</span>() <span class="comment">#L1范数</span></span><br><span class="line">torch.norm(u) <span class="comment">#L2范数</span></span><br></pre></td></tr></table></figure>
<p>对于矩阵，其二范数为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">X</mi><msub><mi mathvariant="normal">∥</mi><mi>F</mi></msub><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msubsup><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup></mrow></msqrt><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\|\mathbf{X}\|_F=\sqrt{\sum_{i=1}^m\sum_{j=1}^nx_{ij}^2}.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathbf">X</span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.2929240000000006em;vertical-align:-1.4137769999999998em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000008em;"><span class="svg-align" style="top:-5.252924em;"><span class="pstrut" style="height:5.252924em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000007em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.795908em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0448000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4129719999999999em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em;"><span class="pstrut" style="height:5.252924em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.3329240000000007em;"><svg width='400em' height='3.3329240000000007em' viewBox='0 0 400000 3332' preserveAspectRatio='xMinYMin slice'><path d='M702 80H40000040
H742v3198l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1
h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170
c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667
219 661 l218 661zM702 80H400000v40H742z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p>
<p>对应代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.norm(torch.ones((<span class="number">4</span>, <span class="number">9</span>))) <span class="comment">#注意norm是平方求和开根号</span></span><br></pre></td></tr></table></figure>
<h5 id="自动微分"><a class="markdownIt-Anchor" href="#自动微分"></a> 自动微分</h5>
<p>我们通过下面来启用自动微分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># torch要求浮点数才能开启自动微分</span></span><br><span class="line">x = torch.arange(<span class="number">4.0</span>) <span class="comment"># x为0到3.0的一个向量</span></span><br><span class="line">x.requires_grad_(<span class="literal">True</span>) <span class="comment">#开启自动微分</span></span><br><span class="line"><span class="comment"># 上面两条语句等同于下面这一条语句</span></span><br><span class="line">x=torch.arange(<span class="number">4.0</span>,requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>下面来看一下如何计算自动微分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">2</span> * torch.dot(x, x)</span><br><span class="line"><span class="comment"># y = x^2</span></span><br><span class="line">y.backward()</span><br><span class="line">x.grad <span class="comment"># 求导数</span></span><br></pre></td></tr></table></figure>
<p>Pytorch会积累梯度，我们需要清除梯度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y = x.<span class="built_in">sum</span>()</span><br><span class="line">y.backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>
<h5 id="非标量变量的反向传播"><a class="markdownIt-Anchor" href="#非标量变量的反向传播"></a> 非标量变量的反向传播</h5>
<p>前面的y是一个标量，这里我们来看一下如果y不是一个标量，此时y对x的导数是一个向量。对于高阶和高维的y和x，求导的结果可以是一个高阶张量。（想象一下一阶导数矩阵Jacob矩阵和二阶导数矩阵Hessian矩阵，阶数越高，此时张量也越高阶）。</p>
<p>如果我们想对指定的变量进行求导，如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span></span><br><span class="line"><span class="comment"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y = x * x</span><br><span class="line"><span class="comment"># 等价于y.backward(torch.ones(len(x)))，对指定的torch.ones进行求导</span></span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad</span><br></pre></td></tr></table></figure>
<h5 id="分离计算"><a class="markdownIt-Anchor" href="#分离计算"></a> 分离计算</h5>
<p>所谓的分离计算，即暂时忽略链式法则。比如</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>z</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y = f(x)\\
z = g(x,y)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span></p>
<p>如果我们将z对x求导，此时由于y是x的函数，需要计算链式法则，而通过分离运算，就不用考虑链式法则了。使用方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y = x * x</span><br><span class="line">u = y.detach()</span><br><span class="line">z = u * x</span><br><span class="line">z.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == u</span><br><span class="line"><span class="comment"># 此时对z = u*x求导，应该就是u</span></span><br><span class="line"><span class="comment"># 分离后，我们仍然可以对y进行梯度计算</span></span><br><span class="line">x.grad.zero_()</span><br><span class="line">y.<span class="built_in">sum</span>().backward()</span><br><span class="line">x.grad == <span class="number">2</span> * x</span><br></pre></td></tr></table></figure>
<p>通过python的控制语句，我们可以实现分段函数，并对其求导：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面是一个分段函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a</span>):</span><br><span class="line">    b = a * <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> b.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    b = b * <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> b.<span class="built_in">sum</span>() &gt; <span class="number">0</span>:</span><br><span class="line">    c = b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">    c = <span class="number">100</span> * b</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"><span class="comment"># 我们对其求导，结果是正常的</span></span><br><span class="line">a = torch.randn(size=(), requires_grad=<span class="literal">True</span>)</span><br><span class="line">d = f(a)</span><br><span class="line">d.backward()</span><br><span class="line">a.grad == d / a <span class="comment"># 和预期一致</span></span><br></pre></td></tr></table></figure>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">首页</a></li>
        
          <li><a href="/about/">关于</a></li>
        
          <li><a href="/archives/">归档</a></li>
        
          <li><a href="/categories/">分类</a></li>
        
          <li><a target="_blank" rel="noopener" href="http://github.com/utmux">项目</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0"><span class="toc-number">1.</span> <span class="toc-text"> 第二章</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6"><span class="toc-number">1.0.1.</span> <span class="toc-text"> 广播机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E6%9C%BA%E5%88%B6"><span class="toc-number">1.0.2.</span> <span class="toc-text"> 索引机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8E%9F%E5%9C%B0%E6%93%8D%E4%BD%9Cin-place-operation"><span class="toc-number">1.0.3.</span> <span class="toc-text"> 原地操作（in-place operation）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tensor%E4%B8%8Enumpy%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E5%8C%96"><span class="toc-number">1.0.4.</span> <span class="toc-text"> tensor与numpy的相互转化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5%E7%94%A8chatgpt"><span class="toc-number">1.0.5.</span> <span class="toc-text"> 读取数据集（可以省略用chatgpt）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%99%E5%85%A5csv"><span class="toc-number">1.0.6.</span> <span class="toc-text"> 写入CSV：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96csv"><span class="toc-number">1.0.7.</span> <span class="toc-text"> 读取CSV</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E6%97%A0%E6%95%88%E6%95%B0%E5%80%BC"><span class="toc-number">1.0.8.</span> <span class="toc-text"> 填充无效数值</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#one-hot%E7%BC%96%E7%A0%81"><span class="toc-number">1.0.9.</span> <span class="toc-text"> one-hot编码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86panda%E8%AF%BB%E5%8F%96%E7%9A%84csv%E6%95%B0%E6%8D%AE%E8%BD%AC%E5%8C%96%E4%B8%BAtensor"><span class="toc-number">1.0.10.</span> <span class="toc-text"> 将panda读取的csv数据转化为tensor</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8C%89%E5%85%83%E7%B4%A0%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E9%BB%98%E8%AE%A4%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E7%AC%A6%E5%8F%B7%E9%83%BD%E6%98%AF%E6%8C%89%E5%85%83%E7%B4%A0%E8%AE%A1%E7%AE%97%E5%8D%B3%E7%82%B9%E5%8A%A0%E7%82%B9%E4%B9%98"><span class="toc-number">1.0.11.</span> <span class="toc-text"> 按元素加减乘除（默认情况下的加减乘除符号都是按元素计算，即点加，点乘）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B1%82%E5%92%8C%E8%BF%90%E7%AE%97"><span class="toc-number">1.0.12.</span> <span class="toc-text"> 求和运算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B1%82%E5%B9%B3%E5%9D%87%E8%BF%90%E7%AE%97"><span class="toc-number">1.0.13.</span> <span class="toc-text"> 求平均运算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%82%B9%E7%A7%AFx%E4%B8%8Ey%E5%9E%82%E7%9B%B4"><span class="toc-number">1.0.14.</span> <span class="toc-text"> 点积（x与y垂直）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="toc-number">1.0.15.</span> <span class="toc-text"> 矩阵乘法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%8C%83%E6%95%B0"><span class="toc-number">1.0.16.</span> <span class="toc-text"> 范数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86"><span class="toc-number">1.0.17.</span> <span class="toc-text"> 自动微分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9D%9E%E6%A0%87%E9%87%8F%E5%8F%98%E9%87%8F%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">1.0.18.</span> <span class="toc-text"> 非标量变量的反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">1.0.19.</span> <span class="toc-text"> 分离计算</span></a></li></ol></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&text=动手深度学习第二章"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&is_video=false&description=动手深度学习第二章"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=动手深度学习第二章&body=Check out this article: https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&title=动手深度学习第二章"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&name=动手深度学习第二章&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://utmux.github.io/2024/07/25/life/%E5%8A%A8%E6%89%8B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E7%AB%A0/&t=动手深度学习第二章"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2025
    YQX
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/categories/">分类</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/utmux">项目</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板！\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功！");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
